# Ultrasound Airway Detection / è¶…éŸ³æ³¢å‘¼å¸é“åµæ¸¬

Object detection and segmentation for difficult airway ultrasound imaging in clinical settings.

ç”¨æ–¼è‡¨åºŠå›°é›£å‘¼å¸é“è¶…éŸ³æ³¢å½±åƒçš„ç‰©ä»¶åµæ¸¬èˆ‡åˆ†å‰²ã€‚

---

## ğŸš€ Quick Start / å¿«é€Ÿé–‹å§‹

### Install / å®‰è£

```bash
git clone https://github.com/jeffhong824/ultrasound-airway-detection.git
cd ultrasound-airway-detection/ultralytics

# Create virtual environment
conda create -n ultrasound-yolo python=3.10
conda activate ultrasound-yolo
# or: python -m venv venv && source venv/bin/activate

# Install
pip install -e .
```

### Train / è¨“ç·´

```bash
python mycodes/train_yolo.py yolo11n det_123 \
  --db_version=3 \
  --es \
  --batch=256 \
  --epochs=15 \
  --device 0,1 \
  --wandb \
  --project="ultrasound-det_123_ES-v3-small-obj" \
  --exp_name="exp10-small-obj-optimized"
```

### Test Example / æ¸¬è©¦ç¯„ä¾‹

Quick test with minimal epochs / å¿«é€Ÿæ¸¬è©¦ï¼ˆæœ€å°‘è¼ªæ•¸ï¼‰ï¼š

```bash
python mycodes/train_yolo.py yolo11n det_123 \
  --db_version=3 \
  --es \
  --batch=128 \
  --epochs=3 \
  --device 0 \
  --wandb \
  --project="test-project" \
  --exp_name="test-exp"
```

### Find Best Epoch / æŸ¥æ‰¾æœ€ä½³ Epoch

```bash
# For production training / æ­£å¼è¨“ç·´
python mycodes/best_epoch.py detect 1 \
  --run_name="yolo11n-det_123-v3-exp10-small-obj-optimized"

# For test training / æ¸¬è©¦è¨“ç·´
python mycodes/best_epoch.py detect 1 \
  --run_name="yolo11n-det_123-v3-test-exp"
```

---

## ğŸ“– Usage / ä½¿ç”¨èªªæ˜

### Basic Command / åŸºæœ¬å‘½ä»¤

```bash
python mycodes/train_yolo.py <model> <database> [options]
```

**Required / å¿…éœ€åƒæ•¸ï¼š**
- `model`: `yolo11n`, `yolo11s`, `yolo11m`, `yolo11l`, `yolo11x` (or `-seg` variants)
- `database`: `det_123`, `seg_45`, `det_678`

**Common Options / å¸¸ç”¨é¸é …ï¼š**

| Parameter | Default | Description / èªªæ˜ |
|-----------|---------|-------------------|
| `--db_version` | `1` | Dataset version: `1`, `2`, `3` |
| `--es` | - | Use Endoscopy dataset suffix |
| `--epochs` | `50` | Training epochs |
| `--batch` | `16` | Batch size (adjust based on GPU memory / æ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´) |
| `--device` | `cuda:0` | Device(s): `0`, `0,1`, `0,1,2,3` for multi-GPU / å¤š GPU |
| `--imgsz` | `640` | Image size: `640`, `1280`, etc. |
| `--wandb` | - | Enable Wandb logging |
| `--project` | auto | Wandb project name |
| `--exp_name` | - | Experiment identifier |
| `--optimizer` | `AdamW` | `SGD`, `Adam`, `AdamW` |
| `--lr0` | `0.01` | Initial learning rate |
| `--box` | `7.5` | Box loss weight (8-12 for small objects) |
| `--cls` | `0.5` | Class loss weight (0.7-1.0 for imbalance) |
| `--dfl` | `1.5` | DFL loss weight (1.5-2.0 recommended) |
| `--use_focal_loss` | - | Enable Focal Loss for small objects |
| `--use_dim_weights` | - | Enable dimension-specific weights |
| `--dim_weights` | - | `W_L W_T W_R W_B` (e.g., `5.0 1.0 5.0 1.0`) |

**Hardware Configuration / ç¡¬é«”é…ç½®ï¼š**
- **Multi-GPU Training / å¤š GPU è¨“ç·´**:
  - Use `--device 0,1` for 2 GPUs / ä½¿ç”¨ 2 å€‹ GPU
  - Use `--device 0,1,2,3` for 4 GPUs / ä½¿ç”¨ 4 å€‹ GPU
  - Batch size will be distributed across GPUs / Batch size æœƒåˆ†æ•£åˆ°å„ GPU
- **Batch Size / æ‰¹æ¬¡å¤§å°**:
  - Adjust `--batch` based on GPU memory / æ ¹æ“š GPU è¨˜æ†¶é«”èª¿æ•´
  - Example: `--batch=256` for large GPU memory / å¤§ GPU è¨˜æ†¶é«”ç¯„ä¾‹
  - With multi-GPU, effective batch size = `--batch Ã— num_GPUs` / å¤š GPU æ™‚ï¼Œæœ‰æ•ˆæ‰¹æ¬¡å¤§å° = `--batch Ã— GPU æ•¸é‡`

**Ultrasound-specific / è¶…éŸ³æ³¢å°ˆç”¨è¨­å®šï¼š**
- `--hsv_h=0` (grayscale images / ç°éšå½±åƒ)
- `--degrees=0 --shear=0 --perspective=0` (no rotation / ç„¡æ—‹è½‰)

See [mycodes/README.md](ultralytics/mycodes/README.md) for detailed documentation.

è©³ç´°æ–‡ä»¶è«‹åƒè€ƒ [mycodes/README.md](ultralytics/mycodes/README.md)ã€‚

---

## ğŸ“ Project Structure / å°ˆæ¡ˆçµæ§‹

```
ultrasound-airway-detection/
â”œâ”€â”€ ultralytics/
â”‚   â”œâ”€â”€ mycodes/           # Training scripts / è¨“ç·´è…³æœ¬
â”‚   â”‚   â”œâ”€â”€ train_yolo.py  # Main training script / ä¸»è¦è¨“ç·´è…³æœ¬
â”‚   â”‚   â””â”€â”€ best_epoch.py  # Find best epoch / æŸ¥æ‰¾æœ€ä½³ epoch
â”‚   â”œâ”€â”€ loss_docs/         # Loss function docs / Loss å‡½æ•¸æ–‡ä»¶
â”‚   â”œâ”€â”€ weights/           # Pretrained models (gitignored) / é è¨“ç·´æ¨¡å‹
â”‚   â””â”€â”€ runs/              # Training outputs (gitignored) / è¨“ç·´è¼¸å‡º
â””â”€â”€ yolo_dataset/          # Dataset (gitignored, 106 GB) / è³‡æ–™é›†
```

---

## ğŸ“¥ Dataset Download / è³‡æ–™é›†ä¸‹è¼‰

Datasets are not included in the repository. Download from Google Drive:

è³‡æ–™é›†ä¸åŒ…å«åœ¨å€‰åº«ä¸­ã€‚å¾ Google Drive ä¸‹è¼‰ï¼š

```bash
# Install dependencies
pip install gdown tqdm

# Option 1: Download complete dataset / ä¸‹è¼‰å®Œæ•´è³‡æ–™é›†
gdown 1Y8Ow9JHqeASeB7Mg4QbAQQPL0RYB8iJB -O yolo_dataset.zip --fuzzy
python -c "from tqdm import tqdm; import zipfile; z=zipfile.ZipFile('yolo_dataset.zip'); z.extractall('.', members=tqdm(z.namelist(), desc='Extracting', unit='files'))"

# Option 2: Download individual datasets / ä¸‹è¼‰å€‹åˆ¥è³‡æ–™é›†
mkdir -p yolo_dataset
cd yolo_dataset

# Download det_123 (with progress bar / é¡¯ç¤ºé€²åº¦æ¢)
gdown 1zKJuabh1PygMH9H3eYq4djTYu3kk7KaP -O det_123.zip --fuzzy
python -c "from tqdm import tqdm; import zipfile; z=zipfile.ZipFile('det_123.zip'); z.extractall('.', members=tqdm(z.namelist(), desc='Extracting det_123', unit='files'))"

# Download det_678 (with progress bar / é¡¯ç¤ºé€²åº¦æ¢)
gdown 1Le-DAEpLFSQpcPHn7bdvbLYYe1-4TV-C -O det_678.zip --fuzzy
python -c "from tqdm import tqdm; import zipfile; z=zipfile.ZipFile('det_678.zip'); z.extractall('.', members=tqdm(z.namelist(), desc='Extracting det_678', unit='files'))"

# Verify structure
ls
# Should see: det_123/, det_678/, seg_45/ (if you downloaded complete dataset)
```

**Links / é€£çµï¼š**
- Complete dataset / å®Œæ•´è³‡æ–™é›†: https://drive.google.com/file/d/1Y8Ow9JHqeASeB7Mg4QbAQQPL0RYB8iJB/view
- det_123.zip: https://drive.google.com/file/d/1zKJuabh1PygMH9H3eYq4djTYu3kk7KaP/view
- det_678.zip: https://drive.google.com/file/d/1Le-DAEpLFSQpcPHn7bdvbLYYe1-4TV-C/view

### Download Model Weights / ä¸‹è¼‰æ¨¡å‹æ¬Šé‡

```bash
# Download yolo11n.pt pretrained weights
gdown 1f8tmI2Jo9rMTPMl0X4cYcVSzHguckAs8 -O ultralytics/weights/yolo11n.pt --fuzzy

# Other weights (yolo11s, yolo11m, etc.) can be downloaded from Ultralytics official releases
# å…¶ä»–æ¬Šé‡ï¼ˆyolo11s, yolo11m ç­‰ï¼‰å¯å¾ Ultralytics å®˜æ–¹ç‰ˆæœ¬ä¸‹è¼‰
```

**Weights link / æ¬Šé‡é€£çµï¼š**
- yolo11n.pt: https://drive.google.com/file/d/1f8tmI2Jo9rMTPMl0X4cYcVSzHguckAs8/view

**Note / æ³¨æ„ï¼š**
- `--fuzzy` required for files >100MB / å¤§æª”æ¡ˆéœ€è¦ `--fuzzy` åƒæ•¸
- Extraction uses Python + tqdm for progress bar (quiet, no verbose logs) / è§£å£“ä½¿ç”¨ Python + tqdm é¡¯ç¤ºé€²åº¦æ¢ï¼ˆå®‰éœæ¨¡å¼ï¼Œç„¡å†—é•·æ—¥èªŒï¼‰
- If tqdm not installed: `pip install tqdm` / è‹¥æœªå®‰è£ tqdmï¼š`pip install tqdm`
- Alternative: use `unzip -q file.zip` for quiet extraction without progress / æ›¿ä»£æ–¹æ¡ˆï¼šä½¿ç”¨ `unzip -q file.zip` å®‰éœè§£å£“ï¼ˆç„¡é€²åº¦æ¢ï¼‰
- Ensure sufficient disk space / ç¢ºä¿æœ‰è¶³å¤ çš„ç£ç¢Ÿç©ºé–“

### Setup Paths for New Machine / æ–°é›»è…¦è·¯å¾‘è¨­ç½®

After downloading datasets and weights, update all paths for your machine:

ä¸‹è¼‰è³‡æ–™é›†å’Œæ¬Šé‡å¾Œï¼Œæ›´æ–°è·¯å¾‘ä»¥é©é…æ‚¨çš„é›»è…¦ï¼š

```bash
# Run setup script to update all paths
bash setup_paths.sh
```

This script automatically updates:
æ­¤è…³æœ¬æœƒè‡ªå‹•æ›´æ–°ï¼š

- âœ… `.env` file `PROJECT_ROOT` variable / `.env` æª”æ¡ˆä¸­çš„ `PROJECT_ROOT` è®Šæ•¸
- âœ… All YAML files `path:` field / æ‰€æœ‰ YAML æª”æ¡ˆçš„ `path:` æ¬„ä½
- âœ… All split files (train.txt, val.txt, test.txt, train_ES.txt, val_ES.txt, test_ES.txt) / æ‰€æœ‰åˆ†å‰²æª”æ¡ˆ
- âœ… Handles all datasets: det_123, det_678, seg_45 / è™•ç†æ‰€æœ‰è³‡æ–™é›†
- âœ… Processes all versions: v1, v2, v3 / è™•ç†æ‰€æœ‰ç‰ˆæœ¬

The script detects the current project root directory and:
è…³æœ¬æœƒè‡ªå‹•åµæ¸¬ç•¶å‰å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸¦ï¼š

- Updates `PROJECT_ROOT` in `.env` (used by `train_yolo.py` and `process_path.py`) / æ›´æ–° `.env` ä¸­çš„ `PROJECT_ROOT`ï¼ˆç”± `train_yolo.py` å’Œ `process_path.py` ä½¿ç”¨ï¼‰
- Replaces old paths in split files and YAML files / æ›¿æ›åˆ†å‰²æª”æ¡ˆå’Œ YAML æª”æ¡ˆä¸­çš„èˆŠè·¯å¾‘

---

## ğŸ”§ Configuration / è¨­å®š

### Environment Variables / ç’°å¢ƒè®Šæ•¸

Copy and edit `.env.example`:

```bash
cp ultralytics/.env.example ultralytics/.env
# Edit .env and set:
# - PROJECT_ROOT: your project root directory path
# - WANDB_API_KEY: your Wandb API key
```

**Required variables / å¿…é ˆè®Šæ•¸ï¼š**
- `PROJECT_ROOT`: Project root directory path / å°ˆæ¡ˆæ ¹ç›®éŒ„è·¯å¾‘
  - Used by `train_yolo.py` and `process_path.py` / ç”± `train_yolo.py` å’Œ `process_path.py` ä½¿ç”¨
  - Example: `PROJECT_ROOT=D:/workplace/project_management/github_project/ultrasound-airway-detection2`
- `WANDB_API_KEY`: Wandb API key (get from https://wandb.ai/authorize)

**Note / æ³¨æ„ï¼š**
- The `setup_paths.sh` script will automatically update `PROJECT_ROOT` in `.env` / `setup_paths.sh` è…³æœ¬æœƒè‡ªå‹•æ›´æ–° `.env` ä¸­çš„ `PROJECT_ROOT`
- Install `python-dotenv` if not already installed: `pip install python-dotenv` / å¦‚æœæœªå®‰è£è«‹å®‰è£ï¼š`pip install python-dotenv`

---

## ğŸ“š Documentation / æ–‡ä»¶

- **Training Guide / è¨“ç·´æŒ‡å—**: [ultralytics/mycodes/README.md](ultralytics/mycodes/README.md)
- **Loss Functions / Loss å‡½æ•¸**: [ultralytics/loss_docs/README.md](ultralytics/loss_docs/README.md)

---

## âš ï¸ Notes / æ³¨æ„äº‹é …

1. **Dataset Path / è³‡æ–™é›†è·¯å¾‘**: Ensure YAML files exist in `yolo_dataset/{database}/v{version}/`
2. **ES Dataset / ES è³‡æ–™é›†**: Using `--es` requires `{database}_ES.yaml` file
3. **GPU Memory / GPU è¨˜æ†¶é«”**: Reduce `--batch` or `--imgsz` if OOM errors occur
4. **Large Files / å¤§æª”æ¡ˆ**: Dataset (106 GB) and model weights are gitignored

---

## ğŸ·ï¸ Version / ç‰ˆæœ¬

Current version: **v0.0.1**

```bash
git fetch --tags
git tag --sort=-creatordate
```

---

## ğŸ“ License / æˆæ¬Š

Based on Ultralytics YOLO. See [LICENSE](ultralytics/LICENSE).

åŸºæ–¼ Ultralytics YOLOã€‚è©³è¦‹ [LICENSE](ultralytics/LICENSE)ã€‚

---

## ğŸ™ Acknowledgments / è‡´è¬

- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
